{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "MFt5G6OpMvar",
   "metadata": {
    "id": "MFt5G6OpMvar"
   },
   "outputs": [],
   "source": [
    "# For google collab:\n",
    "# 1.unzip samples/samples on your local machine. And zip it to samples.zip\n",
    "# 2.load samples.zip to collab\n",
    "# 3.run:\n",
    "\n",
    "\n",
    "# !unzip -q /content/samples.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3bc244",
   "metadata": {
    "id": "1f3bc244"
   },
   "source": [
    "### Capthca solver model via convolutional neural network\n",
    "\n",
    "It is time to reveal the truth: I am Russian.... \n",
    "##### Методология построения модели: \n",
    "1. Так как можель с изображениями, входное изображение подается на вход трем сверточным полносвязным слоям.\n",
    "2. Перед подачей изображения сверточному слою считаются средние и дисперсия по тренировчному набору, затем данные нормируются.\n",
    "3. После каждого свертоночного слоя идут пулинг и батчнорм.\n",
    "4. После последнего сверточного слоя матрица раскрывается в один вектор. Этот вектор поступает на входя пяти параллельным независимым полносвязнанным нейронным сетям с двумя слоями. Каждый слой отвечает за распознавание своей (по счету) буквы.\n",
    "5. Сеть выдает 5 векторов размера 36 (строчные буквы + цифры), каждый выходной вектор сравнивается с меткой класса = букве на соответствующем месте капчи. Критерий -- кросс-энтроопия. Будем минимизировать сумму пяти значений loss функций.\n",
    "\n",
    "##### Методология подбора параметров:\n",
    "1. Построить как можно более сложную сеть, способную обучиться и переобучиться на тренировочной выборке. \n",
    "2. Посредством аугментации входных изображений и дропаута в слоях добиваться уменьшения  переобучения на тестовых данных.\n",
    "\n",
    "Методы аугментации.\n",
    "Так как изображение небольшое, искажения дролжны быть небольшие. Из афинных преобразований сразу исклчается сдвиг, так как модель должна примерно понимать, на каком месте стоит какая буква, по то же причине исключается растяжение. Остается только поворот. \n",
    "Более сложные аугментации, такие как ElasticTransform сильно замедляют загрузку данных и как следствие обучение модели \n",
    "\n",
    "##### Качество модели: \n",
    "Лучший результат, которого удалось добиться на тестовой выборке:  <br>\n",
    "`Test characters error rate = 11.8 %`\n",
    "\n",
    "##### Анализ ошибок:\n",
    "Не вижу смысла проводить анализ ошибок, так как и в чате говорилось, и преподаватели говорили, что можно достичь ошибки меньше 10 и даже меньше 5 процентов. После всех моих усилий мне это не удалось. Большая просьба к проверяющим, подсказать, как улучшить архитектуру моей сети.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d36da6",
   "metadata": {
    "id": "12d36da6"
   },
   "source": [
    "This notebook doesn't contain opportunity of flexible configuration. It might be done by using python-code from `/python` folder and changing `/config/config.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409389e0",
   "metadata": {
    "id": "409389e0"
   },
   "source": [
    "Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd2bf6a",
   "metadata": {
    "id": "8cd2bf6a"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "import torchvision.transforms as transforms\n",
    "import torchsummary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92b24f",
   "metadata": {
    "id": "cd92b24f"
   },
   "source": [
    "Data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9efc66",
   "metadata": {
    "id": "2c9efc66"
   },
   "outputs": [],
   "source": [
    "def get_train_test_names(root_dir, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Create train and test dataset with filenames and labels\n",
    "    \"\"\"\n",
    "    picture_names = [[picture_name, picture_name[: -4]] for picture_name\n",
    "                     in os.listdir(root_dir)]\n",
    "\n",
    "    names_dataframe = pd.DataFrame(picture_names, columns=('filename', 'label'))\n",
    "    names_train, names_test = train_test_split(names_dataframe, \n",
    "                                   test_size=test_size, \n",
    "                                   random_state=42)\n",
    "    return names_train.reset_index(drop=True), names_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_mean_std(dataset_class, names_train, path, transform):\n",
    "    \"\"\"\n",
    "    Get mean and std over all training dataset\n",
    "    \"\"\"\n",
    "    dataset = dataset_class(names_train, PATH, transform)\n",
    "    train_tensors = [dataset[i][0] for i in range(len(names_train))]\n",
    "    train_tensors_stack = torch.stack(train_tensors)\n",
    "    return train_tensors_stack.mean(), train_tensors_stack.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc8b4f",
   "metadata": {
    "id": "c0bc8b4f"
   },
   "source": [
    "Model evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0188db6b",
   "metadata": {
    "id": "0188db6b"
   },
   "outputs": [],
   "source": [
    "def tensor_to_word(dateched_tensor):\n",
    "    dataset = CaptchaDataset(pd.DataFrame(), '')\n",
    "    symbols_array = tuple(map(lambda x: dataset.id_to_symbol[int(x)], \n",
    "              tuple(dateched_tensor)))\n",
    "    return ''.join(map(str, symbols_array))\n",
    "\n",
    "\n",
    "\n",
    "def character_error_rate(net, loader, verbose=False):\n",
    "    \"\"\"\n",
    "    Model quality evaluation\n",
    "    enable verbose to see word pairs: errors in recognition \n",
    "    \"\"\"\n",
    "    net.train(False)\n",
    "    with torch.no_grad():\n",
    "        errors = 0\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs[:,0,:], 1)\n",
    "            predicted, labels = predicted.detach().cpu().numpy(), \\\n",
    "                    labels.detach().cpu().numpy()[0]\n",
    "            \n",
    "            errors += np.count_nonzero(predicted - labels)\n",
    "            if verbose:\n",
    "                print(\"error:\", tensor_to_word(predicted),\n",
    "                 tensor_to_word(labels))\n",
    "                \n",
    "    return errors / (LETTERS_AMOUNT * len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0938b78",
   "metadata": {
    "id": "e0938b78"
   },
   "source": [
    "Model configuration and training routine  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "367fbd32",
   "metadata": {
    "id": "367fbd32"
   },
   "outputs": [],
   "source": [
    "def train_model(net, criterion, optimizer, trainloader, num_epochs=10):\n",
    "    net.train(True)\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"{epoch=}\")\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs).to(device)\n",
    "            loss = 0\n",
    "            for letter_num in range(LETTERS_AMOUNT):\n",
    "                loss += criterion(outputs[:, letter_num], labels[letter_num])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'{loss=}')\n",
    "    print('Finished Training')\n",
    "    return net\n",
    "\n",
    "\n",
    "\n",
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None, verbose=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.verbose = verbose\n",
    "        self.symbols = list(map(str, range(10))) + list(string.ascii_lowercase) \n",
    "        self.symbol_to_id = {key: value for value, key in enumerate(self.symbols)}\n",
    "        self.id_to_symbol = {value: key for value, key in enumerate(self.symbols)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "            \n",
    "        \n",
    "        img_name = os.path.join(self.root_dir, self.dataframe['filename'][index])\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        \n",
    "        label = torch.tensor(np.array(\n",
    "            [self.symbol_to_id[idx] for idx in self.dataframe['label'][index]]))   \n",
    "        \n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(image)\n",
    "        \n",
    "        return img_tensor, label\n",
    "    \n",
    "\n",
    "class CaptchaSolverNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CaptchaSolverNet, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=(3, 6), padding=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(128, 64, kernel_size=(3, 6), padding=(1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, kernel_size=(3, 6), padding=(1, 1))\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "\n",
    "        # Full connected layers for each letter\n",
    "        self.partials1 = torch.nn.ModuleList(tuple((\n",
    "            nn.Linear(in_features=4224, out_features=512) \n",
    "            for _ in range(LETTERS_AMOUNT))))\n",
    "\n",
    "\n",
    "        self.partials2 = torch.nn.ModuleList(tuple((\n",
    "            nn.Linear(in_features=512, out_features=36) \n",
    "            for _ in range(LETTERS_AMOUNT))))\n",
    "\n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        outputs = []\n",
    "        for letter_num in range(LETTERS_AMOUNT):\n",
    "            letter = self.partials1[letter_num](x)\n",
    "            letter = F.relu(letter)\n",
    "            letter = self.bn4(letter)\n",
    "            letter = self.dropout(letter)\n",
    "\n",
    "            letter = self.partials2[letter_num](letter)\n",
    "            letter = F.relu(letter)\n",
    "\n",
    "            outputs.append(letter)\n",
    "        result = torch.stack(outputs)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1528f367",
   "metadata": {
    "id": "1528f367"
   },
   "source": [
    "### __main__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208062b5",
   "metadata": {
    "id": "208062b5"
   },
   "source": [
    "Configure path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "467c516d",
   "metadata": {
    "id": "467c516d"
   },
   "outputs": [],
   "source": [
    "folder_path = os.getcwd() \n",
    "PATH = os.path.abspath(os.path.join(folder_path, os.pardir, 'samples', 'samples'))\n",
    "\n",
    "\n",
    "\n",
    "# uncomment if working in collab: \n",
    "# PATH = '/content/samples'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16002580",
   "metadata": {
    "id": "16002580"
   },
   "source": [
    "Configure device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c5203af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c5203af",
    "outputId": "6e432c6b-b706-4964-d3e6-b5dbec850a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    "     dev = \"cuda:0\" \n",
    "else: \n",
    "     dev = \"cpu\" \n",
    "device = torch.device(dev) \n",
    "print(f'{device=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041aa50",
   "metadata": {
    "id": "3041aa50"
   },
   "source": [
    "Since we solve 5-letters captcha set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52f5a220",
   "metadata": {
    "id": "52f5a220"
   },
   "outputs": [],
   "source": [
    "LETTERS_AMOUNT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1bd096",
   "metadata": {
    "id": "df1bd096"
   },
   "source": [
    "Read data from file, calcute statistics, transform, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76224a24",
   "metadata": {
    "id": "76224a24"
   },
   "outputs": [],
   "source": [
    "transform_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "names_train, names_test = get_train_test_names(PATH)\n",
    "sample_mean, sample_std = get_mean_std(CaptchaDataset, names_train, \n",
    "                                       PATH, transform_to_tensor)\n",
    "\n",
    "transform_to_tensor_and_norm_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(sample_mean, sample_std),\n",
    "    transforms.RandomAffine(degrees=(5))])\n",
    "\n",
    "transform_to_tensor_and_norm_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(sample_mean, sample_std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e8649",
   "metadata": {
    "id": "301e8649"
   },
   "source": [
    "Conffgure datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3accf95",
   "metadata": {
    "id": "d3accf95"
   },
   "outputs": [],
   "source": [
    "trainset = CaptchaDataset(names_train, PATH, transform_to_tensor_and_norm_train)\n",
    "testset = CaptchaDataset(names_test, PATH, transform_to_tensor_and_norm_test,\n",
    "                        verbose=True)\n",
    "\n",
    "batch_size = 24\n",
    "num_workers = 2\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a459c",
   "metadata": {
    "id": "ce4a459c"
   },
   "source": [
    "Training model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e60bc6df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e60bc6df",
    "outputId": "f5957de2-6751-4076-8f68-b4ac0d281941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 128, 50, 197]           2,432\n",
      "         MaxPool2d-2          [-1, 128, 25, 98]               0\n",
      "       BatchNorm2d-3          [-1, 128, 25, 98]             256\n",
      "            Conv2d-4           [-1, 64, 25, 95]         147,520\n",
      "         MaxPool2d-5           [-1, 64, 12, 47]               0\n",
      "       BatchNorm2d-6           [-1, 64, 12, 47]             128\n",
      "            Conv2d-7           [-1, 32, 12, 44]          36,896\n",
      "         MaxPool2d-8            [-1, 32, 6, 22]               0\n",
      "       BatchNorm2d-9            [-1, 32, 6, 22]              64\n",
      "           Linear-10                  [-1, 512]       2,163,200\n",
      "      BatchNorm1d-11                  [-1, 512]           1,024\n",
      "          Dropout-12                  [-1, 512]               0\n",
      "           Linear-13                   [-1, 36]          18,468\n",
      "           Linear-14                  [-1, 512]       2,163,200\n",
      "      BatchNorm1d-15                  [-1, 512]           1,024\n",
      "          Dropout-16                  [-1, 512]               0\n",
      "           Linear-17                   [-1, 36]          18,468\n",
      "           Linear-18                  [-1, 512]       2,163,200\n",
      "      BatchNorm1d-19                  [-1, 512]           1,024\n",
      "          Dropout-20                  [-1, 512]               0\n",
      "           Linear-21                   [-1, 36]          18,468\n",
      "           Linear-22                  [-1, 512]       2,163,200\n",
      "      BatchNorm1d-23                  [-1, 512]           1,024\n",
      "          Dropout-24                  [-1, 512]               0\n",
      "           Linear-25                   [-1, 36]          18,468\n",
      "           Linear-26                  [-1, 512]       2,163,200\n",
      "      BatchNorm1d-27                  [-1, 512]           1,024\n",
      "          Dropout-28                  [-1, 512]               0\n",
      "           Linear-29                   [-1, 36]          18,468\n",
      "================================================================\n",
      "Total params: 11,100,756\n",
      "Trainable params: 11,100,756\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 16.37\n",
      "Params size (MB): 42.35\n",
      "Estimated Total Size (MB): 58.75\n",
      "----------------------------------------------------------------\n",
      "epoch=0\n",
      "loss=tensor(17.8552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=1\n",
      "loss=tensor(17.0448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=2\n",
      "loss=tensor(15.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=3\n",
      "loss=tensor(15.6522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=4\n",
      "loss=tensor(12.8373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=5\n",
      "loss=tensor(13.5427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=6\n",
      "loss=tensor(11.0128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=7\n",
      "loss=tensor(11.7484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=8\n",
      "loss=tensor(11.2033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=9\n",
      "loss=tensor(9.4508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=10\n",
      "loss=tensor(9.9422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=11\n",
      "loss=tensor(9.1284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=12\n",
      "loss=tensor(5.4465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=13\n",
      "loss=tensor(5.4449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=14\n",
      "loss=tensor(4.8647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=15\n",
      "loss=tensor(4.8461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=16\n",
      "loss=tensor(4.4895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=17\n",
      "loss=tensor(4.5038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=18\n",
      "loss=tensor(3.5616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=19\n",
      "loss=tensor(3.6524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=20\n",
      "loss=tensor(3.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=21\n",
      "loss=tensor(2.1486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=22\n",
      "loss=tensor(2.4797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=23\n",
      "loss=tensor(2.9822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=24\n",
      "loss=tensor(4.0090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=25\n",
      "loss=tensor(3.6208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=26\n",
      "loss=tensor(5.5002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=27\n",
      "loss=tensor(1.3533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=28\n",
      "loss=tensor(2.8655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=29\n",
      "loss=tensor(1.4714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=30\n",
      "loss=tensor(2.2635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=31\n",
      "loss=tensor(1.2367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=32\n",
      "loss=tensor(4.0611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=33\n",
      "loss=tensor(1.6561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=34\n",
      "loss=tensor(2.3501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=35\n",
      "loss=tensor(1.6383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=36\n",
      "loss=tensor(1.0855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=37\n",
      "loss=tensor(2.0777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=38\n",
      "loss=tensor(1.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=39\n",
      "loss=tensor(0.8068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=40\n",
      "loss=tensor(0.7789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=41\n",
      "loss=tensor(1.6564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=42\n",
      "loss=tensor(1.3443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=43\n",
      "loss=tensor(2.2816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=44\n",
      "loss=tensor(0.8391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=45\n",
      "loss=tensor(0.5456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=46\n",
      "loss=tensor(0.5188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=47\n",
      "loss=tensor(2.9549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=48\n",
      "loss=tensor(0.8653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=49\n",
      "loss=tensor(0.4655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=50\n",
      "loss=tensor(0.5381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=51\n",
      "loss=tensor(0.4312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=52\n",
      "loss=tensor(0.5756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=53\n",
      "loss=tensor(0.5255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=54\n",
      "loss=tensor(1.2009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=55\n",
      "loss=tensor(0.3943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=56\n",
      "loss=tensor(0.5144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=57\n",
      "loss=tensor(0.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=58\n",
      "loss=tensor(1.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=59\n",
      "loss=tensor(0.7377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=60\n",
      "loss=tensor(0.3523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=61\n",
      "loss=tensor(0.7084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=62\n",
      "loss=tensor(0.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=63\n",
      "loss=tensor(0.4857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=64\n",
      "loss=tensor(1.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=65\n",
      "loss=tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=66\n",
      "loss=tensor(0.7241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=67\n",
      "loss=tensor(0.6392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=68\n",
      "loss=tensor(1.2968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=69\n",
      "loss=tensor(0.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=70\n",
      "loss=tensor(1.2915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=71\n",
      "loss=tensor(0.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=72\n",
      "loss=tensor(1.4314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=73\n",
      "loss=tensor(0.5811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=74\n",
      "loss=tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=75\n",
      "loss=tensor(0.7365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=76\n",
      "loss=tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=77\n",
      "loss=tensor(1.4513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=78\n",
      "loss=tensor(0.6153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=79\n",
      "loss=tensor(1.1536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=80\n",
      "loss=tensor(1.5524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=81\n",
      "loss=tensor(1.3563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=82\n",
      "loss=tensor(1.1032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=83\n",
      "loss=tensor(0.8521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=84\n",
      "loss=tensor(0.7592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=85\n",
      "loss=tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=86\n",
      "loss=tensor(1.3527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=87\n",
      "loss=tensor(0.2894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=88\n",
      "loss=tensor(0.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=89\n",
      "loss=tensor(0.1776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=90\n",
      "loss=tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=91\n",
      "loss=tensor(0.4867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=92\n",
      "loss=tensor(0.2378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=93\n",
      "loss=tensor(0.2327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=94\n",
      "loss=tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=95\n",
      "loss=tensor(0.4758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=96\n",
      "loss=tensor(0.4480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=97\n",
      "loss=tensor(0.2567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=98\n",
      "loss=tensor(1.0553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=99\n",
      "loss=tensor(0.3323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=100\n",
      "loss=tensor(0.2355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=101\n",
      "loss=tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=102\n",
      "loss=tensor(0.5556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=103\n",
      "loss=tensor(0.5800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=104\n",
      "loss=tensor(0.1730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=105\n",
      "loss=tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=106\n",
      "loss=tensor(0.2054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=107\n",
      "loss=tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=108\n",
      "loss=tensor(0.1620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=109\n",
      "loss=tensor(1.1219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=110\n",
      "loss=tensor(1.0310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=111\n",
      "loss=tensor(0.3284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=112\n",
      "loss=tensor(0.3052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=113\n",
      "loss=tensor(0.3808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=114\n",
      "loss=tensor(0.6265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=115\n",
      "loss=tensor(0.3977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=116\n",
      "loss=tensor(0.2084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=117\n",
      "loss=tensor(0.5146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=118\n",
      "loss=tensor(1.0704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=119\n",
      "loss=tensor(0.4665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=120\n",
      "loss=tensor(0.9745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=121\n",
      "loss=tensor(0.1606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=122\n",
      "loss=tensor(0.1106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=123\n",
      "loss=tensor(0.1454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=124\n",
      "loss=tensor(0.1687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=125\n",
      "loss=tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=126\n",
      "loss=tensor(0.2430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=127\n",
      "loss=tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=128\n",
      "loss=tensor(0.2298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=129\n",
      "loss=tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=130\n",
      "loss=tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=131\n",
      "loss=tensor(0.3211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=132\n",
      "loss=tensor(0.1963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=133\n",
      "loss=tensor(0.3202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=134\n",
      "loss=tensor(0.2979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=135\n",
      "loss=tensor(0.1499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=136\n",
      "loss=tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=137\n",
      "loss=tensor(0.1739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=138\n",
      "loss=tensor(0.3111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=139\n",
      "loss=tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=140\n",
      "loss=tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=141\n",
      "loss=tensor(0.1300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=142\n",
      "loss=tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=143\n",
      "loss=tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=144\n",
      "loss=tensor(0.1014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=145\n",
      "loss=tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=146\n",
      "loss=tensor(0.1559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=147\n",
      "loss=tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=148\n",
      "loss=tensor(0.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "epoch=149\n",
      "loss=tensor(0.5956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = CaptchaSolverNet()\n",
    "net = net.to(device)\n",
    "\n",
    "torchsummary.summary(net, (1, 50, 200))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "net = train_model(net, criterion, optimizer, trainloader, num_epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d016c9",
   "metadata": {
    "id": "86d016c9"
   },
   "source": [
    "Evaluate model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34b89fde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34b89fde",
    "outputId": "31f84500-883a-45b4-ffc6-7b467bbd6276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trian characters error rate = 0.021261682242990656\n",
      "Test characters error rate = 0.13271028037383178\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_workers = 1\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "print(f'Trian characters error rate = {character_error_rate(net, trainloader)}')\n",
    "print(f'Test characters error rate = {character_error_rate(net, testloader)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# Uncomment below to see missclassification pairs\n",
    "# \"\"\"\n",
    "# print(f'Trian characters error rate = {character_error_rate(net, \n",
    "# trainloader, verbose=True)}')\n",
    "# print(f'Test characters error rate = {character_error_rate(net, \n",
    "# testloader, verbose=True)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nrF4Lx1PQywf",
   "metadata": {
    "id": "nrF4Lx1PQywf"
   },
   "outputs": [],
   "source": [
    "# on local machine:\n",
    "torch.save(net.state_dict(), os.path.abspath(os.path.join(folder_path, os.pardir, \n",
    "                                                          'result_model','result')))\n",
    "\n",
    "\n",
    "\n",
    "# On collab\n",
    "# torch.save(net.state_dict(), 'result')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
